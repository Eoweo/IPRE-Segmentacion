{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ceb40e9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/workspace/cmorenor/.conda/envs/pyenv/lib/python3.10/site-packages/albumentations/__init__.py:28: UserWarning: A new version of Albumentations is available: '2.0.5' (you have '2.0.4'). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import time\n",
    "import torch\n",
    "import psutil\n",
    "import random\n",
    "import copy as c\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import parameter as p\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from scipy import ndimage\n",
    "import albumentations as A\n",
    "from multiprocessing import Pool\n",
    "from collections import defaultdict\n",
    "from torch.utils.data import Dataset\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torchvision.transforms.functional import rotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90be6cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def initialize_patient_splits(abs_path, test_ratio=p.RATIO):\n",
    " \n",
    "    PATIENT_SPLITS = {\"train\": set(), \"test\": set()}\n",
    "    csv_path = os.path.join(abs_path, \"archive\", \"train.csv\")\n",
    "    data = pd.read_csv(csv_path)\n",
    "\n",
    "    # Extract unique patient IDs\n",
    "    patient_ids = list(set(row['ImageId'].split('_')[0] for _, row in data.iterrows()))\n",
    "\n",
    "    # Shuffle and split\n",
    "    random.shuffle(patient_ids)\n",
    "    if p.CHOP_PATIENT:\n",
    "        split_index = int(round(p.CHOP_PATIENT_VALUE * test_ratio, 0))\n",
    "        max_index = int(p.CHOP_PATIENT_VALUE)\n",
    "    else:\n",
    "        split_index = int(round((len(patient_ids)) * test_ratio, 0))\n",
    "        max_index = int(len(patient_ids))\n",
    "\n",
    "    max_index = int(round(split_index/p.RATIO, 0))\n",
    "    PATIENT_SPLITS[\"train\"] = set(patient_ids[:split_index])\n",
    "    PATIENT_SPLITS[\"test\"] = set(patient_ids[split_index:max_index])\n",
    "\n",
    "    print(\"Patient split initialized. Train:\", len(PATIENT_SPLITS[\"train\"]), \"Test:\", len(PATIENT_SPLITS[\"test\"]))\n",
    "    return PATIENT_SPLITS\n",
    "\n",
    "def load_jpg_dataset_generator(abs_path, target_size=(128, 128), PATIENT_SPLITS = dict(), dataset_type=\"test\", block_id=set(), inference = p.INFERENCE):\n",
    "\n",
    "    csv_path = os.path.join(abs_path, \"archive\", \"train.csv\")\n",
    "    data = pd.read_csv(csv_path)\n",
    "    if p.CHOP_DATA:\n",
    "        data = data[:p.CHOP_DATA_VALUE]\n",
    "\n",
    "    image_dir = os.path.join(abs_path, \"archive\", \"images\", \"images\")\n",
    "    mask_dir = os.path.join(abs_path, \"archive\", \"masks\", \"masks\")\n",
    "\n",
    "    with tqdm(total=len(data), desc=f\"Uploading {dataset_type} dataset\", dynamic_ncols=True, leave=True) as pbar:\n",
    "        i = 0\n",
    "        for _, row in data.iterrows():\n",
    "            image_name = row[\"ImageId\"]\n",
    "            mask_name = row[\"MaskId\"]\n",
    "\n",
    "            patient_id = image_name.split(\"_\")[0]\n",
    "\n",
    "            if not inference: \n",
    "                if patient_id in block_id or (patient_id not in block_id and patient_id not in PATIENT_SPLITS[dataset_type]): #pass if it's a block patient\n",
    "                    pbar.update(1)\n",
    "                    continue\n",
    "            i += 1\n",
    "\n",
    "            image = Image.open(os.path.join(image_dir, image_name)).convert(\"L\")\n",
    "            mask = Image.open(os.path.join(mask_dir, mask_name)).convert(\"RGB\")\n",
    "\n",
    "            if p.RESIZE:\n",
    "                image = np.array(image.resize(target_size), dtype=np.float32) / 255.0\n",
    "                mask = np.array(mask.resize(target_size), dtype=np.float32) / 255.0\n",
    "            else:\n",
    "                image = np.array(image, dtype=np.float32) / 255.0\n",
    "                mask = np.array(mask, dtype=np.float32) / 255.0\n",
    "\n",
    "            threshold = 0.2\n",
    "            mask = (mask[:, :, 2] > threshold) * mask[:, :, 2] # takes the blue color of the mask only\n",
    "\n",
    "            pbar.update(1)\n",
    "            used_memory =  psutil.virtual_memory().used / (1024**3)\n",
    "            total_memory = psutil.virtual_memory().total / (1024**3)\n",
    "\n",
    "            # Set progress bar postfix with estimated time left\n",
    "            pbar.set_postfix({\n",
    "                \"Mem\": f\"{used_memory:.2f} / {total_memory:.2f} GB\",\n",
    "                \"N_Img\": f\"{i}\"})\n",
    "            \n",
    "            yield image, mask, image_name  # Instead of storing, yield one image at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27702c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_brightness_and_saturation(image):\n",
    "    if len(image.shape) == 2 or image.shape[2] == 1:  # Grayscale image\n",
    "        # For grayscale: Brightness = mean pixel value, Saturation = 0\n",
    "        brightness = np.mean(image) / 255.0\n",
    "        saturation = 0.0\n",
    "    else:  # RGB image\n",
    "        hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "        brightness = hsv[..., 2].mean() / 255.0  # Value channel\n",
    "        saturation = hsv[..., 1].mean() / 255.0   # Saturation channel\n",
    "    return brightness, saturation\n",
    "\n",
    "def get_adaptive_augmentation_pipeline(image):\n",
    "\n",
    "    height, width = image.shape[:2]\n",
    "\n",
    "    brightness, saturation = calculate_brightness_and_saturation(image)\n",
    "\n",
    "    brightness_strength = max(0.1, 0.3 - brightness)\n",
    "    contrast_strength = max(0.1, 1.0 - saturation)\n",
    "\n",
    "    # Transformations that affect both image and mask\n",
    "    geometric_transforms = [\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.RandomCrop(height=height, width=width, p=0.8),\n",
    "        A.PadIfNeeded(min_height=512, min_width=512, border_mode=0, p=0.8),\n",
    "        A.Rotate(limit=10, p=0.8),\n",
    "    ]\n",
    "\n",
    "    # Only apply color transforms to the image\n",
    "    #color_transforms = [\n",
    "    #    A.OneOf([\n",
    "    #        A.RandomBrightnessContrast(\n",
    "    #            brightness_limit=(-0.1, brightness_strength),\n",
    "    #            contrast_limit=(0.5, contrast_strength),\n",
    "    #            p=1.0\n",
    "    #        ),\n",
    "    #        A.ColorJitter(\n",
    "    #            brightness=0.2 * (1 - brightness),\n",
    "    #            contrast=0.2 * (1 - saturation),\n",
    "    #            saturation=0.2 * (1 - saturation),\n",
    "    #            hue=0.1,\n",
    "    #            p=1.0\n",
    "    #        ),\n",
    "    #    ], p=0.8)\n",
    "    #]\n",
    "\n",
    "    # Full pipeline\n",
    "    return A.Compose(\n",
    "        transforms = geometric_transforms + #color_transforms + \n",
    "        [A.Resize(height, width)], additional_targets={'mask': 'mask'}\n",
    "    )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f41fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MainDataset(Dataset):\n",
    "    def __init__(self, data, augmentation=p.AUGMENTATION, dataset_type=\"test\"):\n",
    "        self.images = []\n",
    "        self.masks = []\n",
    "        self.id = []\n",
    "        self.dataset_type = dataset_type\n",
    "        self.augmentation = augmentation\n",
    "        # Load dataset into memory\n",
    "        for img, mask, id in data:\n",
    "            self.images.append(img)\n",
    "            self.masks.append(mask)\n",
    "            self.id.append(id)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        mask = self.masks[idx]\n",
    "        id = self.id[idx]\n",
    "\n",
    "        # Normalize image values to [0, 255] if needed\n",
    "        image = image.astype(np.uint8) if image.max() <= 1.0 else image\n",
    "\n",
    "        if self.augmentation and self.dataset_type == \"Training\":\n",
    "            transform = get_adaptive_augmentation_pipeline(image)  # <-- Call here\n",
    "            augmented = transform(image=image, mask=mask)\n",
    "            image = augmented[\"image\"]\n",
    "            mask = augmented[\"mask\"]\n",
    "\n",
    "        # Convert image and mask to torch tensors\n",
    "        if len(image.shape) == 2:  # Grayscale\n",
    "            image = torch.tensor(image, dtype=torch.float32).unsqueeze(0)\n",
    "        else:  # RGB\n",
    "            image = torch.tensor(image.transpose(2, 0, 1), dtype=torch.float32)\n",
    "\n",
    "        mask = torch.tensor(mask, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "        return image, mask, id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e28ab695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient split initialized. Train: 40 Test: 10\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "get_adaptive_augmentation_pipeline() missing 1 required positional argument: 'image'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 7\u001b[0m\n\u001b[1;32m      2\u001b[0m train_generator \u001b[38;5;241m=\u001b[39m load_jpg_dataset_generator(p\u001b[38;5;241m.\u001b[39mPATH_CT_MARCOPOLO, target_size\u001b[38;5;241m=\u001b[39mp\u001b[38;5;241m.\u001b[39mRESIZE_VALUE, \n\u001b[1;32m      3\u001b[0m                                              PATIENT_SPLITS \u001b[38;5;241m=\u001b[39m patient_splits, dataset_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,  block_id\u001b[38;5;241m=\u001b[39mp\u001b[38;5;241m.\u001b[39mBLOCK_ID)\n\u001b[1;32m      4\u001b[0m test_generator \u001b[38;5;241m=\u001b[39m load_jpg_dataset_generator(p\u001b[38;5;241m.\u001b[39mPATH_CT_MARCOPOLO, target_size\u001b[38;5;241m=\u001b[39mp\u001b[38;5;241m.\u001b[39mRESIZE_VALUE, \n\u001b[1;32m      5\u001b[0m                                             PATIENT_SPLITS \u001b[38;5;241m=\u001b[39m patient_splits, dataset_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m, block_id\u001b[38;5;241m=\u001b[39mp\u001b[38;5;241m.\u001b[39mBLOCK_ID)\n\u001b[0;32m----> 7\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mMainDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugmentation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAUGMENTATION\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTraining\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m val_dataset \u001b[38;5;241m=\u001b[39m MainDataset(test_generator, augmentation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dataset_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m val2_dataset \u001b[38;5;241m=\u001b[39m MainDataset(test_generator, augmentation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, dataset_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 8\u001b[0m, in \u001b[0;36mMainDataset.__init__\u001b[0;34m(self, data, augmentation, dataset_type)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset_type \u001b[38;5;241m=\u001b[39m dataset_type\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maugmentation \u001b[38;5;241m=\u001b[39m augmentation\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform \u001b[38;5;241m=\u001b[39m \u001b[43mget_adaptive_augmentation_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m augmentation \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Load dataset into memory\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m img, mask, \u001b[38;5;28mid\u001b[39m \u001b[38;5;129;01min\u001b[39;00m data:\n",
      "\u001b[0;31mTypeError\u001b[0m: get_adaptive_augmentation_pipeline() missing 1 required positional argument: 'image'"
     ]
    }
   ],
   "source": [
    "patient_splits = initialize_patient_splits(p.PATH_CT_MARCOPOLO)\n",
    "train_generator = load_jpg_dataset_generator(p.PATH_CT_MARCOPOLO, target_size=p.RESIZE_VALUE, \n",
    "                                             PATIENT_SPLITS = patient_splits, dataset_type=\"train\",  block_id=p.BLOCK_ID)\n",
    "test_generator = load_jpg_dataset_generator(p.PATH_CT_MARCOPOLO, target_size=p.RESIZE_VALUE, \n",
    "                                            PATIENT_SPLITS = patient_splits, dataset_type=\"test\", block_id=p.BLOCK_ID)\n",
    "\n",
    "train_dataset = MainDataset(train_generator, augmentation=p.AUGMENTATION, dataset_type=\"Training\")\n",
    "val_dataset = MainDataset(test_generator, augmentation=False, dataset_type=\"Test\")\n",
    "val2_dataset = MainDataset(test_generator, augmentation=True, dataset_type=\"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec84871",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
